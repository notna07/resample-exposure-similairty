{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b28ffd",
   "metadata": {},
   "source": [
    "# Distance Measure for Heterogeneous Tabular Data\n",
    "\n",
    "There has been many attempts to define a reliable distance measure for heterogeneous tabulr data (e.g., categorical, binary, and numerical features). The most notable is the Gower distance, which is a generalization of the Manhattan distance. But it is paticularly unstable when only a few features of a type are present in the data.\n",
    "\n",
    "In the following we define a new distance metric that builds on the previous work of Gower and others. The new distance metric is based on the following principles:\n",
    "1. Like the Gower, and Estabrook-rogers etc. the new distance metric is a collection of distance measures for each attribute. \n",
    "2. The distance for categorical features are based on the Hamming distance.\n",
    "3. The distance for numerical and ordinal features are based on the normalised Manhattan distance.\n",
    "4. Each attribute-wise distance measure is weighted by the probability of accidentally selecting the value for the attribute of the source point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad4a486b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: Balance Scale\n",
      "Number of rows: 625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>right-distance</th>\n",
       "      <th>right-weight</th>\n",
       "      <th>left-distance</th>\n",
       "      <th>left-weight</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   right-distance  right-weight  left-distance  left-weight class\n",
       "0               1             1              1            1     B\n",
       "1               2             1              1            1     R\n",
       "2               3             1              1            1     R\n",
       "3               4             1              1            1     R\n",
       "4               5             1              1            1     R"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load datasets\n",
    "import uci_dataset as dataset\n",
    "import seaborn as sns\n",
    "from prepare_data import _clean_up_data, uci_dataset_id_import\n",
    "\n",
    "ID_nums = [ 44, 53, 174, 42, 95, 342, 212, 763, 39, 52, 292, 887, 537, 451, 16, 176, 43, 545, 149, 151, 110, 379, 186, 267, 146, 147, 80, 563, 107, 186]\n",
    "ID_diff = [1, 257, 12, 14, 143, 15, 17, 145, 144, 22, 544, 161, 419, 73, 336, 83, 856, 857, 90, 101, 105, 244]\n",
    "\n",
    "df = uci_dataset_id_import(12, silent_import=False)\n",
    "# df = dataset.load_parkinson()\n",
    "# df = sns.load_dataset('titanic')\n",
    "\n",
    "print(\"Number of rows:\", df.shape[0])\n",
    "\n",
    "# _clean_up_data(df, 'class')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba96344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_name</th>\n",
       "      <th>method</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>autism</td>\n",
       "      <td>L2</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.879433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>autism</td>\n",
       "      <td>L2_OHE</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.865248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>autism</td>\n",
       "      <td>REX</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.964539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>autism</td>\n",
       "      <td>Gower</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.964539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>balance_scale</td>\n",
       "      <td>L2</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.856000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>thoracic_surgery</td>\n",
       "      <td>Gower</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.782587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>wisconsin_bc</td>\n",
       "      <td>L2</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.946764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>wisconsin_bc</td>\n",
       "      <td>L2_OHE</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.946764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>wisconsin_bc</td>\n",
       "      <td>REX</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.762406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>wisconsin_bc</td>\n",
       "      <td>Gower</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>0.946397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>464 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              df_name  method    metric     value\n",
       "0              autism      L2  accuracy  0.879433\n",
       "1              autism  L2_OHE  accuracy  0.865248\n",
       "2              autism     REX  accuracy  0.964539\n",
       "3              autism   Gower  accuracy  0.964539\n",
       "4       balance_scale      L2  accuracy  0.856000\n",
       "..                ...     ...       ...       ...\n",
       "459  thoracic_surgery   Gower  f1_score  0.782587\n",
       "460      wisconsin_bc      L2  f1_score  0.946764\n",
       "461      wisconsin_bc  L2_OHE  f1_score  0.946764\n",
       "462      wisconsin_bc     REX  f1_score  0.762406\n",
       "463      wisconsin_bc   Gower  f1_score  0.946397\n",
       "\n",
       "[464 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"01_knn_cls_results.csv\")\n",
    "\n",
    "# grab the part ot he dataframe with balanced type\n",
    "# df = df[df['type']=='most_cats']\n",
    "\n",
    "# take the dataframe, make accuracy, precision and recall columns into long format\n",
    "df = df.melt(id_vars=['df_name', 'method'], value_vars=['accuracy', 'precision', 'recall', 'f1_score'],\n",
    "             var_name='metric', value_name='value')\n",
    "df\n",
    "# df.rename({'df_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2481a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from critdd import Diagrams # Diagrams is the 2D version of Diagram\n",
    "import numpy as np\n",
    "\n",
    "# construct a sequence of CD diagrams\n",
    "treatment_names = df[\"method\"].unique()\n",
    "diagram_names = df[\"metric\"].unique()\n",
    "Xs = [] # collect an (n,k)-shaped matrix for each diagram\n",
    "for n in diagram_names:\n",
    "    diagram_df = df[df.metric == n].pivot(\n",
    "        index = \"df_name\",\n",
    "        columns = \"method\",\n",
    "        values = \"value\"\n",
    "    )[treatment_names] # ensure a fixed order of treatments\n",
    "    Xs.append(diagram_df.to_numpy())\n",
    "two_dimensional_diagram = Diagrams(\n",
    "    np.stack(Xs),\n",
    "    diagram_names = diagram_names,\n",
    "    treatment_names = treatment_names,\n",
    "    maximize_outcome = True\n",
    ")\n",
    "\n",
    "# customize the style of the plot and export to PDF\n",
    "two_dimensional_diagram.to_file(\n",
    "    \"2d_example.pdf\",\n",
    "    preamble = \"\\n\".join([ # colors are defined before \\begin{document}\n",
    "        \"\\\\definecolor{color1}{HTML}{84B818}\",\n",
    "        \"\\\\definecolor{color2}{HTML}{D18B12}\",\n",
    "        \"\\\\definecolor{color3}{HTML}{1BB5B5}\",\n",
    "        \"\\\\definecolor{color4}{HTML}{F85A3E}\",\n",
    "        \"\\\\definecolor{color5}{HTML}{4B6CFC}\",\n",
    "        \"\\\\definecolor{color6}{HTML}{F8A300}\",\n",
    "        \"\\\\definecolor{color7}{HTML}{FF69B4}\",\n",
    "    ]),\n",
    "    axis_options = { # style the plot\n",
    "        \"cycle list\": \",\".join([ # define the markers for treatments\n",
    "            \"{color1,mark=*}\",\n",
    "            \"{color2,mark=diamond*}\",\n",
    "            \"{color3,mark=triangle,semithick}\",\n",
    "            \"{color4,mark=square,semithick}\",\n",
    "            \"{color5,mark=pentagon,semithick}\",\n",
    "            \"{color6,mark=star,semithick}\",\n",
    "            \"{color7,mark=oplus,semithick}\",\n",
    "        ]),\n",
    "        \"width\": \"\\\\axisdefaultwidth\",\n",
    "        \"height\": \"0.75*\\\\axisdefaultheight\",\n",
    "        \"title\": \"critdd\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d9006",
   "metadata": {},
   "source": [
    "### Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6bf42737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: ['NSP', 'DS', 'Nzeros', 'Tendency', 'CLASS']\n",
      "Train set shape: (1700, 23)\n",
      "Test set shape: (426, 23)\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# encode categorical features\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "def encode_categorical_features(df, cat_features):\n",
    "    encoder = OrdinalEncoder()\n",
    "    df[cat_features] = encoder.fit_transform(df[cat_features])\n",
    "    return df\n",
    "\n",
    "def get_categorical_features(df, unique_threshold=10):\n",
    "    cat_features = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    for col in df.select_dtypes(include=['int', 'float']).columns:\n",
    "        if df[col].nunique() <= unique_threshold:\n",
    "            cat_features.append(col)\n",
    "    return cat_features\n",
    "\n",
    "def split_data(df, test_size=0.2, random_state=42):  \n",
    "    # Split the data into train and test sets\n",
    "    train, test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    return train, test\n",
    "\n",
    "def process_data(df, class_col='class'):\n",
    "    cat_features = get_categorical_features(df)\n",
    "    print(\"Categorical features:\", cat_features)\n",
    "    df = encode_categorical_features(df, cat_features)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    df = df[[class_col] + [col for col in df.columns if col != class_col]]\n",
    "    cat_features.remove(class_col)\n",
    "\n",
    "    train, test = split_data(df)\n",
    "    return train, test, cat_features\n",
    "\n",
    "train, test, cat_cols = process_data(d3, 'NSP')\n",
    "\n",
    "print(\"Train set shape:\", train.shape)\n",
    "print(\"Test set shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "775dcfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8110040156190678"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(train.iloc[:, 1:], train.iloc[:,0])\n",
    "preds = neigh.predict(test.iloc[:, 1:])\n",
    "\n",
    "f1_score(test.iloc[:,0], preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "74a1d0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 1700)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9043687560648586"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use gower distance\n",
    "import gower\n",
    "\n",
    "def gower_knn(train, test, k=3):\n",
    "    # Create a KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='precomputed')\n",
    "    \n",
    "    # Compute the Gower distance matrix\n",
    "    gower_train = gower.gower_matrix(train.iloc[:, 1:], train.iloc[:, 1:])\n",
    "    gower_test = gower.gower_matrix(test.iloc[:, 1:], train.iloc[:, 1:])\n",
    "    print(gower_test.shape)\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(gower_train, train.iloc[:, 0])\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    predictions = knn.predict(gower_test)\n",
    "    return predictions\n",
    "\n",
    "preds = gower_knn(train, test, k=3)\n",
    "\n",
    "f1_score(test.iloc[:,0], preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2eb4f0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lautrup\\AppData\\Local\\Temp\\1\\ipykernel_13092\\4047891434.py:20: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  bin_width = np.ceil(n**(1/3) * std / (3.5 * (np.percentile(samples, 75) - np.percentile(samples, 25)))).astype(int)\n",
      "C:\\Users\\lautrup\\AppData\\Local\\Temp\\1\\ipykernel_13092\\4047891434.py:20: RuntimeWarning: invalid value encountered in cast\n",
      "  bin_width = np.ceil(n**(1/3) * std / (3.5 * (np.percentile(samples, 75) - np.percentile(samples, 25)))).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 221)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5579559617781471"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _scott_ref_rule(samples):\n",
    "    \"\"\"Function for doing the Scott reference rule to calcualte number of bins needed to \n",
    "    represent the nummerical values.\n",
    "    \n",
    "    Args:\n",
    "        samples (array-like) : The data to be binned.\n",
    "    \n",
    "    Returns:\n",
    "        array : bin edges\n",
    "    \n",
    "    Example:\n",
    "        >>> _scott_ref_rule([1,2,3,4,5])\n",
    "        array([1., 2., 3., 4., 5.])\n",
    "    \"\"\"\n",
    "    std = np.std(samples)\n",
    "    n = len(samples)\n",
    "    bin_width = np.ceil(n**(1/3) * std / (3.5 * (np.percentile(samples, 75) - np.percentile(samples, 25)))).astype(int)\n",
    "\n",
    "    min_edge = min(samples); max_edge = max(samples)\n",
    "    N = min(abs(int((max_edge-min_edge)/bin_width)),10000); Nplus1 = N + 1\n",
    "    return np.linspace(min_edge, max_edge, Nplus1)\n",
    "\n",
    "def lautrup_distance_matrix(df_x, df_y=None, cat_features=None):\n",
    "    \"\"\"\n",
    "    Compute the Lautrup distance matrix between two dataframes.\n",
    "    \"\"\"\n",
    "\n",
    "    # join the datasets\n",
    "    if df_y is None:\n",
    "        df_y = df_x\n",
    "    df = pd.concat((df_x,df_y), axis=0)\n",
    "\n",
    "    num_features = [col for col in df.columns if col not in cat_features]\n",
    "\n",
    "    normalisation, feat_range = {}, {}\n",
    "    for col in num_features:\n",
    "        if np.issubdtype(df[col].dtype, np.floating):\n",
    "            normalisation[col] = 1-1/(max(len(_scott_ref_rule(df[col])),2)-1)\n",
    "        else:\n",
    "            normalisation[col] = 1-1/df[col].nunique()\n",
    "\n",
    "        feat_range[col] = df[col].max()-df[col].min()\n",
    "\n",
    "    for col in cat_features:\n",
    "        normalisation[col] = 1-1/df[col].nunique()\n",
    "\n",
    "    # create the distance matrix\n",
    "    dist_matrix = np.zeros((len(df_x), len(df_y)))\n",
    "\n",
    "    for i, row in enumerate(df_x.iterrows()):\n",
    "        for j, col in enumerate(df_y.iterrows()):\n",
    "            for col_name in num_features:\n",
    "                dist_matrix[i,j] += normalisation[col_name]*np.abs(row[1][col_name] - col[1][col_name]) / feat_range[col_name]\n",
    "            for col_name in cat_features:\n",
    "                if row[1][col_name] != col[1][col_name]:\n",
    "                    dist_matrix[i,j] += normalisation[col_name]\n",
    "    return dist_matrix\n",
    "\n",
    "def lautrup_knn(train, test, k=3, cat_features=None):\n",
    "    # Create a KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='precomputed')\n",
    "    \n",
    "    # Compute the Gower distance matrix\n",
    "    _train = lautrup_distance_matrix(train.iloc[:, 1:], train.iloc[:, 1:], cat_features)\n",
    "    _test = lautrup_distance_matrix(test.iloc[:, 1:], train.iloc[:, 1:], cat_features)\n",
    "    print(_test.shape)\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(_train, train.iloc[:, 0])\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    predictions = knn.predict(_test)\n",
    "    return predictions\n",
    "\n",
    "cat_vars = ['menopause', 'node-caps', 'breast', 'breast-quad', 'irradiat']\n",
    "preds = lautrup_knn(train, test, k=3, cat_features=cat_vars)\n",
    "\n",
    "f1_score(test.iloc[:,0], preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d2f12876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lautrup\\AppData\\Local\\Temp\\1\\ipykernel_13092\\3680320830.py:23: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  bin_width = np.ceil(n**(1/3) * std / (3.5 * (np.percentile(samples, 75) - np.percentile(samples, 25)))).astype(int)\n",
      "C:\\Users\\lautrup\\AppData\\Local\\Temp\\1\\ipykernel_13092\\3680320830.py:23: RuntimeWarning: invalid value encountered in cast\n",
      "  bin_width = np.ceil(n**(1/3) * std / (3.5 * (np.percentile(samples, 75) - np.percentile(samples, 25)))).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 1700)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9545681900554648"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import ndarray\n",
    "from pandas import Series\n",
    "\n",
    "def _scott_ref_rule(samples):\n",
    "    \"\"\"Function for doing the Scott reference rule to calcualte number of bins needed to \n",
    "    represent the nummerical values.\n",
    "    \n",
    "    Args:\n",
    "        samples (array-like) : The data to be binned.\n",
    "    \n",
    "    Returns:\n",
    "        array : bin edges\n",
    "    \n",
    "    Example:\n",
    "        >>> _scott_ref_rule([1,2,3,4,5])\n",
    "        array([1., 2., 3., 4., 5.])\n",
    "    \"\"\"\n",
    "    std = np.std(samples)\n",
    "    n = len(samples)\n",
    "    bin_width = np.ceil(n**(1/3) * std / (3.5 * (np.percentile(samples, 75) - np.percentile(samples, 25)))).astype(int)\n",
    "\n",
    "    min_edge = min(samples); max_edge = max(samples)\n",
    "    N = min(abs(int((max_edge-min_edge)/bin_width)),10000); Nplus1 = N + 1\n",
    "    return np.linspace(min_edge, max_edge, Nplus1)\n",
    "\n",
    "def prob_reroll_cat(counts: Series, target: int):\n",
    "    \"\"\"Calculate the probability of rolling a categorical variable into the target variable.\"\"\"\n",
    "    return counts.get(target, 0)\n",
    "\n",
    "def prob_reroll_num(histogram: ndarray, binning: ndarray,  target: float):\n",
    "    \"\"\"Calculate the probability of rolling a numerical variable into the target variable.\"\"\"\n",
    "    # Get the counts of each bin in the variable\n",
    "    \n",
    "    bin_index = np.digitize(target, binning) - 1\n",
    "    if bin_index < 0 or bin_index >= len(histogram):\n",
    "        return 0\n",
    "    prob = histogram[bin_index] / sum(histogram)\n",
    "    return prob\n",
    "\n",
    "def rerollers_distance_matrix(df_x, df_y=None, cat_features=None):\n",
    "    \"\"\"\n",
    "    Compute the rerollers distance matrix between two dataframes.\n",
    "    (the chance that randomly resampling the variable will make it into the target variable)\n",
    "    \"\"\"\n",
    "\n",
    "    # join the datasets\n",
    "    if df_y is None:\n",
    "        df_y = df_x\n",
    "    df = pd.concat((df_x,df_y), axis=0)\n",
    "\n",
    "    num_features = [col for col in df.columns if col not in cat_features]\n",
    "\n",
    "    bin_range, histogram, feat_range = {}, {}, {}\n",
    "    for col in num_features:\n",
    "        if np.issubdtype(df[col].dtype, np.floating):\n",
    "            bin_range[col] = _scott_ref_rule(df[col])\n",
    "            histogram[col] = np.histogram(df[col], bins=bin_range[col])[0]\n",
    "        else:\n",
    "            bin_range[col] = np.arange(df[col].nunique()+1)\n",
    "            histogram[col] = np.histogram(df[col], bins=bin_range[col])[0]\n",
    "            \n",
    "        feat_range[col] = df[col].max()-df[col].min()\n",
    "    \n",
    "    cat_counts = {}\n",
    "    for col in cat_features:\n",
    "        cat_counts[col] = df[col].value_counts(normalize=True)\n",
    "\n",
    "    # create the distance matrix\n",
    "    dist_matrix = np.zeros((len(df_x), len(df_y)))\n",
    "\n",
    "    for i, row in enumerate(df_x.iterrows()):\n",
    "        for j, col in enumerate(df_y.iterrows()):\n",
    "            for col_name in num_features:\n",
    "                dist_matrix[i,j] += (1-prob_reroll_num(histogram[col_name], bin_range[col_name], j))*np.abs(row[1][col_name] - col[1][col_name]) / feat_range[col_name]\n",
    "            for col_name in cat_features:\n",
    "                if row[1][col_name] != col[1][col_name]:\n",
    "                    dist_matrix[i,j] += (1-prob_reroll_cat(cat_counts[col_name], j))\n",
    "    return dist_matrix\n",
    "\n",
    "def reroll_knn(train, test, k=3, cat_features=None):\n",
    "    # Create a KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, metric='precomputed')\n",
    "    \n",
    "    # Compute the Gower distance matrix\n",
    "    _train = rerollers_distance_matrix(train.iloc[:, 1:], train.iloc[:, 1:], cat_features)\n",
    "    _test = rerollers_distance_matrix(test.iloc[:, 1:], train.iloc[:, 1:], cat_features)\n",
    "    print(_test.shape)\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(_train, train.iloc[:, 0])\n",
    "    \n",
    "    # Predict the labels for the test set\n",
    "    predictions = knn.predict(_test)\n",
    "    return predictions\n",
    "\n",
    "preds = reroll_knn(train, test, k=3, cat_features=cat_cols)\n",
    "\n",
    "f1_score(test.iloc[:,0], preds, average='macro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
